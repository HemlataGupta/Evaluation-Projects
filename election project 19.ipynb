{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl the ECI election statistics\n",
    "\n",
    "<http://eci.nic.in/eci_main1/ElectionStatistics.aspx> has PDFs of past election results. Let's first download them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import urlopen, urlretrieve\n",
    "from urlparse import urljoin\n",
    "from lxml.html import parse\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'http://eci.nic.in/eci_main1/ElectionStatistics.aspx'\n",
    "tree = parse(urlopen(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all rows from the second table in <div id=\"c\">\n",
    "# Then download the PDFs. (This can take a few hours.)\n",
    "for tr in tree.findall('//*[@id=\"c\"]/table[2]//tr'):\n",
    "    state = tr.find('td').text\n",
    "    if state is None:\n",
    "        continue\n",
    "    for link in tr.findall('.//a'):\n",
    "        year = link.text.replace('.', '').replace(' ', '').strip()\n",
    "        filename = (state + ' ' + year + '.pdf').lower().strip().replace(' ', '-')\n",
    "        if not exists(filename):\n",
    "            urlretrieve(urljoin(base, link.get('href')), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the tough bit: parsing the PDFs for information.\n",
    "\n",
    "First use [xpdf](http://www.foolabs.com/xpdf/) to convert PDFs into text.\n",
    "\n",
    "Then, use the following script to convert them all into an `assembly.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import logging\n",
    "\n",
    "columns = [\n",
    "    'ST_NAME',\n",
    "    'YEAR',\n",
    "    'AC_NO',\n",
    "    'AC_NAME',\n",
    "    'AC_TYPE',\n",
    "    '#',\n",
    "    'NAME',\n",
    "    'SEX',\n",
    "    'AGE',\n",
    "    'CATEGORY',\n",
    "    'PARTY',\n",
    "    'VOTES',\n",
    "]\n",
    "\n",
    "header_map = {\n",
    "    'GORY': 'CATEGORY',\n",
    "    'TOTAL': 'VOTES'\n",
    "}\n",
    "\n",
    "def pdf_parse(filename, out):\n",
    "    name = filename.split('.')[0].split('-')\n",
    "    state = ' '.join(s.title() for s in name[:-1])\n",
    "    year = name[-1].strip()\n",
    "\n",
    "    headers, last_ac_no, start_parsing = None, 0, False\n",
    "    rows = 0\n",
    "    for line in open(filename):\n",
    "        if not start_parsing:\n",
    "            # DETAILED RESULTS. Ignore all lines before this phrase\n",
    "            if 'DETAILED RESULTS' in line:\n",
    "                start_parsing = True\n",
    "            # Exceptions: goa-1989.txt, uttar-pradesh-1996.txt, gujarat-2012.txt (image file)\n",
    "            if re.search('CANDIDATE.*PARTY.*VOTES', line):\n",
    "                start_parsing = True \n",
    "            if not start_parsing:\n",
    "                continue\n",
    "        else:\n",
    "            # Uttar Pradesh 2002 has a Statistical report at the END of the PDF. Ignore it.\n",
    "            if 'STATISTICAL REPORT' in line:\n",
    "                start_parsing = False\n",
    "                continue\n",
    "\n",
    "        # CONSTITUENCY NAME\n",
    "        # If the row mentions a Constituency, or begins with 3+ spaces and a number,\n",
    "        if line.startswith('Constituency') or re.match('\\s{18,}\\d+\\s*\\.\\s*\\w', line):\n",
    "            # Ignore the word Constituency, and any non-digits, at the beginning.\n",
    "            # Remove anything that occurs after 3 spaces. e.g. Total electors are added at the end\n",
    "            ac = re.sub('Constituency[^\\d]*', '', line, re.I).strip()\n",
    "            ac = re.sub('NUMBER *OF *SEATS.*', '', ac, re.I).strip()\n",
    "            ac = re.sub('TOTAL *ELECTORS', '', ac, re.I).strip()\n",
    "            # Sometimes, there's just a blank word Constituency -- ignore these.\n",
    "            if not ac:\n",
    "                continue\n",
    "\n",
    "            # Get the AC number, name and type\n",
    "            match = re.match(r'(\\d+)[^A-Za-z]*([A-Za-z0-9 \\.\\-\\(\\)]*)', ac)\n",
    "            ac_no = int(match.group(1))\n",
    "            ac_name_type = match.group(2).strip().upper()\n",
    "            match = re.search(r'\\((SC|ST|GEN|BL)\\)', ac_name_type)\n",
    "            if match:\n",
    "                start, end = match.start(), match.end()\n",
    "                ac_name = ac_name_type[:start].strip() \n",
    "                ac_type = ac_name_type[start+1:end-1]\n",
    "            else:\n",
    "                ac_name = ac_name_type\n",
    "                ac_type = 'GEN'\n",
    "\n",
    "            # Ensure that AC number is consecutive for the same \n",
    "            if ac_no > last_ac_no + 1:\n",
    "                logging.warn('AC No skipped: %s %s: %d to %d',\n",
    "                             state, year, last_ac_no, ac_no)\n",
    "            last_ac_no = ac_no\n",
    "            continue\n",
    "\n",
    "        # HEADER ROW\n",
    "        # Only header lines have both CANDIDATE and PARTY mentioned\n",
    "        if re.search(r'CANDIDATE.*PARTY', line):\n",
    "            # Ignore Name & Address... just consider everything else after that\n",
    "            headers = re.sub('^.*CANDIDATE(.*NAME)?(.*ADDRESS)?', '', line.strip()).split()\n",
    "            # Standardise headers\n",
    "            headers = [header_map.get(h, h) for h in headers]\n",
    "            continue\n",
    "\n",
    "        # CANDIDATE ROW\n",
    "        # If the row starts with a number, it's probably a candidate.\n",
    "        # Some exceptions: West Bengal 1951: \"14 - Page 16 of 38\". Ignore page numbers\n",
    "        # TODO: The candidate name is often split over 2 rows. Handle that.\n",
    "        match = re.match(r'^\\s{,20}([\\d\\,]+)\\D.*?(\\w.*)', line)\n",
    "        if match and not ('Page ' in line and ' of ' in line):\n",
    "            # Note: not all fields are one word.\n",
    "            # E.g. \"Aa S P\" is a UP party. But we'll correct these manually.\n",
    "            fields = line.strip().split()\n",
    "            \n",
    "            # If candidate is uncontested, the last field (%) is often missing. e.g. Nagaland 1998\n",
    "            # Replace this with 100%\n",
    "            if len(fields) and 'uncontested' in fields[-1].lower() and headers[-2] == 'VOTES':\n",
    "                fields.append('100%')\n",
    "\n",
    "            fields = dict(zip(headers, fields[len(fields) - len(headers):]))\n",
    "            rank = match.group(1).replace(',', '')\n",
    "            name = match.group(2).split('  ')[0].strip()\n",
    "            \n",
    "            # Some 2008-2009 elections have TWO numbers before the name (prev year rank?)\n",
    "            # E.g. Chhattisgarh 2008, Delhi 2008, J&K 2008, Arunachal Pradesh 2009, etc\n",
    "            # If the first part of name is a number (with decimal or comma), use that as rank\n",
    "            parts = name.split()\n",
    "            first_part = parts[0].replace('.', '').replace(',', '')\n",
    "            if first_part.isdigit():\n",
    "                rank, name = first_part, ' '.join(parts[1:])\n",
    "                \n",
    "            out.writerow([\n",
    "                state,\n",
    "                year,\n",
    "                ac_no,\n",
    "                ac_name,\n",
    "                ac_type,\n",
    "                rank,\n",
    "                name,\n",
    "                # Punjab 1997 uses 'W' instead of 'F' for gender\n",
    "                fields.get('SEX', '').replace('W', 'F'),\n",
    "                fields.get('AGE', ''),\n",
    "                fields.get('CATEGORY', ''),\n",
    "                fields.get('PARTY', ''),\n",
    "                fields.get('VOTES', '').lower().replace('uncontested', ''),\n",
    "            ])\n",
    "            rows += 1\n",
    "    \n",
    "    if rows < 2:\n",
    "        logging.warn('Only %d candidates: %s %s' % (rows, state, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:AC No skipped: Assam 1951: 24 to 28\n",
      "WARNING:root:AC No skipped: Assam 1967: 0 to 2\n",
      "WARNING:root:AC No skipped: Assam 1972: 0 to 4\n",
      "WARNING:root:AC No skipped: Assam 1972: 21 to 31\n",
      "WARNING:root:AC No skipped: Assam 1983: 31 to 36\n",
      "WARNING:root:AC No skipped: Assam 1983: 64 to 67\n",
      "WARNING:root:AC No skipped: Assam 1983: 70 to 73\n",
      "WARNING:root:AC No skipped: Assam 1983: 74 to 79\n",
      "WARNING:root:AC No skipped: Assam 1983: 80 to 82\n",
      "WARNING:root:AC No skipped: Assam 1983: 98 to 100\n",
      "WARNING:root:AC No skipped: Assam 1983: 117 to 121\n",
      "WARNING:root:AC No skipped: Assam 1996: 51 to 53\n",
      "WARNING:root:AC No skipped: Assam 1996: 96 to 98\n",
      "WARNING:root:AC No skipped: Assam 1996: 103 to 105\n",
      "WARNING:root:AC No skipped: Assam 1996: 123 to 125\n",
      "WARNING:root:AC No skipped: Delhi 1983: 29 to 31\n",
      "WARNING:root:AC No skipped: Gujarat 1975: 62 to 64\n",
      "WARNING:root:Only 0 candidates: Gujarat 2012\n",
      "WARNING:root:AC No skipped: Himachal Pradesh 1990: 55 to 57\n",
      "WARNING:root:AC No skipped: Manipur 1990: 0 to 3\n",
      "WARNING:root:AC No skipped: Manipur 1990: 3 to 6\n",
      "WARNING:root:AC No skipped: Manipur 1990: 19 to 22\n",
      "WARNING:root:AC No skipped: Orissa 1974: 57 to 59\n",
      "WARNING:root:AC No skipped: Punjab 2007: 11 to 13\n",
      "WARNING:root:AC No skipped: Rajasthan 1993: 76 to 78\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1974: 206 to 208\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1991: 382 to 384\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1991: 392 to 395\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1991: 395 to 399\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1993: 232 to 234\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1993: 278 to 280\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1993: 393 to 395\n",
      "WARNING:root:AC No skipped: Uttar Pradesh 1996: 384 to 386\n",
      "WARNING:root:AC No skipped: Uttarakhand 2007: 58 to 60\n",
      "WARNING:root:AC No skipped: West Bengal 1971: 128 to 130\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "with open('assembly.csv', 'w') as f:\n",
    "    out = csv.writer(f, lineterminator='\\n')\n",
    "    out.writerow(columns)\n",
    "    for filename in glob.glob('*.txt'):\n",
    "        pdf_parse(filename, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validations\n",
    "\n",
    "I've manually validated these. Some of the above warnings are because the PDF itself skipped the number. (Some of these are clearly errors in the PDF, e.g. Beas is missing in Punjab 2007, though the summary exists).\n",
    "\n",
    "However, only two errors are real, and must be fixed manually:\n",
    "\n",
    "- Uttar Pradesh, 1951: for consituencies 6, 53 and 81, there are 2 rows for constituences, not 1. (This may not visible in the warnings above -- I fixed it manually.)\n",
    "- Gujarat, 2012: the file has images, not text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the 2013 Indian election results\n",
    "\n",
    "The main portal that holds the results is <http://eciresults.nic.in/>. Of these, the constituency-wise results <http://eciresults.nic.in/ConstituencywiseS2653.htm> appears to have the maximum detail, with the following fields:\n",
    "\n",
    "- State\n",
    "- Constituency\n",
    "- Candidate\n",
    "- Party\n",
    "- Votes\n",
    "\n",
    "So let's scrape that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(url):\n",
    "    \"\"\"Retrieves a URL as an lxml tree, cached where possible\"\"\"\n",
    "    filename = '.cache.' + sha256(url).hexdigest()\n",
    "    if not os.path.exists(filename):\n",
    "        html = urlretrieve(url, filename)\n",
    "    return parse(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constituencies(url):\n",
    "    \"\"\"Yields dicts with state, state_code, constituency, constituency_code.\"\"\"\n",
    "    tree = get(url)\n",
    "\n",
    "    # States and codes are stored in Javascript, like this:\n",
    "    #     if (st.value == 'S26') {\n",
    "    #         strValues = document.getElementById('HdnFldChhattisgarh').value;\n",
    "    # This is a crude parsing of that code\n",
    "    statecode = re.findall('st.value *=+ *\\'([^\\']+).*?HdnFld([^\\']+)',\n",
    "                           tree.findall('.//script')[0].text, re.S)\n",
    "    statecode = {state:code for code, state in statecode}\n",
    "    \n",
    "    # Constituency codes are in hidden input fields. Format is:\n",
    "    # code,constituency; code,constituency; ...\n",
    "    for el in tree.findall('.//input[@id]'):\n",
    "        id = el.get('id', '').strip()\n",
    "        if id.startswith('HdnFld'):\n",
    "            state = id.replace('HdnFld', '')\n",
    "            for row in el.get('value').split(';'):\n",
    "                row = row.strip()\n",
    "                if row:\n",
    "                    cells = row.split(',')\n",
    "                    yield {\n",
    "                        'YEAR': '2013',\n",
    "                        'ST_NAME': state,\n",
    "                        'ST_CODE': statecode.get(state),\n",
    "                        'AC_NAME': cells[1],\n",
    "                        'AC_NO': cells[0]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(url):\n",
    "    \"\"\"For a constituency URL, yields dicts with candidate, party, votes.\"\"\"\n",
    "    tree = get(url)\n",
    "\n",
    "    # Results are inside a table in a <div id=\"div1\">\n",
    "    count = 1\n",
    "    for row in tree.findall('.//*[@id=\"div1\"]//tr'):\n",
    "        cells = row.findall('td')\n",
    "        if len(cells) >= 3:\n",
    "            yield {\n",
    "                '#': str(count),\n",
    "                'NAME': cells[0].text.strip(),\n",
    "                # Party Proutist Bloc India is wrongly split into 2 cells.\n",
    "                # E.g. Delhi 2013 at CHHATARPUR\n",
    "                'PARTY': ' '.join(c.text.strip() for c in cells[1:-1]),\n",
    "                'VOTES': cells[-1].text.strip(),\n",
    "            }\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assembly.csv', 'a') as f:\n",
    "    out = csv.writer(f, lineterminator='\\n')\n",
    "    for place in constituencies('http://eciresults.nic.in/ConstituencywiseS2653.htm'):\n",
    "        url = 'http://eciresults.nic.in/Constituencywise{:s}{:s}.htm?ac={:s}'.format(\n",
    "            place['ST_CODE'], place['AC_NO'], place['AC_NO'])\n",
    "        # print 'Debug: scraping', place['ST_CODE'], place['AC_NO']\n",
    "        for result in results(url):\n",
    "            result.update(place)\n",
    "            out.writerow([result.get(f, '').encode('cp1252') for f in columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardise and manually override data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('assembly.csv', dtype=object)\n",
    "\n",
    "# In some PDFs, the rows are repeated. Remove these.\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure AC, party and candidate names in upper case, for standardisation, and replace multiple spaces with single spaces. (State names are standardised anyway, so let's not worry about their case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AC_NAME'] = data['AC_NAME'].str.upper().str.replace('\\s+', ' ')\n",
    "data['NAME'] = data['NAME'].str.upper().str.replace('\\s+', ' ')\n",
    "data['PARTY'] = data['PARTY'].str.upper().str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `override.csv` has data in the same format as `assembly.csv` that overrides the data. The primary keys are `ST_NAME`, `YEAR`, `AC_NO`, `#`. Let's first make sure that these are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_keys = ['ST_NAME', 'YEAR', 'AC_NO', '#']\n",
    "if len(data[primary_keys].drop_duplicates()) != len(data):\n",
    "    logging.warn('Duplicate rows found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "override = pd.read_csv('override.csv', dtype=object).set_index(primary_keys)\n",
    "data = data.set_index(primary_keys)\n",
    "data.update(override)\n",
    "data = data.reset_index()\n",
    "\n",
    "# data.update will not replace NaNs. So use \"-\" in override.csv instead of blank.\n",
    "# Finally, replace '-' with NaNs.\n",
    "data['VOTES'].replace({'-': pd.np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's rename columns to standardise names of parties, constituencies, etc. This is from the manually prepared `rename.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = pd.read_csv('rename.csv', dtype=object)\n",
    "for column, indices in rename.groupby('Column').groups.iteritems():\n",
    "    lookup = rename.ix[indices].set_index('Field')['Value'].to_dict()\n",
    "    data[column] = data[column].replace(lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of votes needs to be standardised. Let's ensure that the only places where VOTES is NA are where the candidate is uncontested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['VOTES'] = data['VOTES'].astype(float)\n",
    "num_contestants = data.groupby(['ST_NAME', 'YEAR', 'AC_NO'])['NAME'].transform(lambda x: [len(x)] * len(x))\n",
    "data['VOTES'][num_contestants == 1] = pd.np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranks are often incorrect in the source data. Correct that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['#'] = data.groupby(['ST_NAME', 'YEAR', 'AC_NO'])['VOTES'].transform(\n",
    "    lambda x: x.rank(ascending=False, method='min').fillna(1).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it back in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('assembly.csv', index=False, na_rep='', float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting facts\n",
    "\n",
    "1. Maximum candidates:\n",
    "    - 1,033 in Modakurichi, TN 1996. 28 women. 88 people got ZERO votes -- didn't even vote for themselves. \n",
    "    - 301 in Belgaum, KA 1985. 54 women (highest ever)\n",
    "    - ~260 somewhere in TN\n",
    "\n",
    "1. 312 candidates got 0 votes, i.e. didn't even vote for themselves.\n",
    "   TN again leads the list. 88 in Modakurichi, TN 1996.\n",
    "   \n",
    "   - 4 in Pallipet, TN 1991.\n",
    "   - 3 in Aravakurichi, TN 1991.\n",
    "   - 2 in Dharmapur, Assam 1983.\n",
    "   - 2 in Madhepur, Bihar, 1995.\n",
    "   \n",
    "   By party:\n",
    "   \n",
    "   - 136 from INC\n",
    "   - 130 independents\n",
    "   - 34 from NC\n",
    "   - 5 from AHL\n",
    "   - Just one each from the others (no BJP though)\n",
    "   \n",
    "   In the last 10 years, this has happened only with 3 INC ST candidates in Arunachal Pradesh 2009, who forgot to vote for themselves.\n",
    "   \n",
    "1. Largest number of votes: NAROTTAMBHAI PATEL (BJP) won with 5,84,098 votes at Chorasi in Gujarat 2007 against DHANANI JANAKBHAI (INC) who got 2,37,158 votes.\n",
    "\n",
    "1. Largest % margin of victory: Who got the single largest % of votes in a constituency?\n",
    "\n",
    "1. Clean sweeps by a party: When all has a party swept a state assembly election?\n",
    "\n",
    "1. Anti-incumbency: Which states have switched parties in successive elections, and when?\n",
    "\n",
    "More ideas are at <http://eci.nic.in/eci_main1/intresting_states.aspx>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
